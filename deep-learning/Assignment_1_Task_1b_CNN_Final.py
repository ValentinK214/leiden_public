# -*- coding: utf-8 -*-
"""Assignment 1 - task1b CNN final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rlH6oHk7LGiy2JqICDfOL-JIGirT4BS9

# Read me

You can run this file without having to load any external data.

This notebook took about 1.5 hour to run.
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import tensorflow as tf
from tensorflow import keras
from keras import layers
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense
from sklearn.model_selection import train_test_split
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# Load the Fashion MNIST dataset
fashion_mnist = tf.keras.datasets.fashion_mnist
(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()
x_train_full = x_train_full.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_train, x_temp, y_train, y_temp = train_test_split(x_train_full, y_train_full, test_size=0.2, shuffle=True, random_state=42)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, shuffle=True, random_state=42)
print("Training data shape:", x_train.shape, y_train.shape)
print("Validation data shape:", x_val.shape, y_val.shape)
print("Test data shape:", x_test.shape, y_test.shape)

class_names_fashion_mnist = [
    'T-shirt/top',  # 0
    'Trouser',      # 1
    'Pullover',     # 2
    'Dress',        # 3
    'Coat',         # 4
    'Sandal',       # 5
    'Shirt',        # 6
    'Sneaker',      # 7
    'Bag',          # 8
    'Ankle boot'    # 9
]

def plot_training_history(history):
    train_accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']
    train_loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1, len(train_accuracy) + 1)

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()

    plt.tight_layout()
    plt.show()


def test_accuracy(model,x_test,y_test,class_names):
    y_pred_prob= model.predict(x_test)
    y_pred= np.argmax(y_pred_prob, axis=1)
    conf_matrix = confusion_matrix(y_test, y_pred)
    print(conf_matrix)
    print(classification_report(y_test, y_pred, target_names=class_names))

"""<h1>Model taken from the book and used as the baseline approach <h1/>"""

cnn_base = keras.models.Sequential([
 keras.layers.Conv2D(64, 7, activation="relu", padding="same",
 input_shape=[28, 28, 1]),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
 keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
 keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Flatten(),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(64, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(10, activation="softmax")
])
cnn_base.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_base.summary()

history_cnn_base=cnn_base.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_base.evaluate(x_test,y_test)

"""<h1>Model with increasing channels per layer<h1/>"""

cnn_channel_increase=keras.models.Sequential([
    keras.layers.Input(shape=(28, 28, 1)),
    keras.layers.Conv2D(64,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(128,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(236,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(512,(3,3),activation="relu"),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(512,activation="relu"),
    keras.layers.Dense(10,activation="softmax")
])
cnn_channel_increase.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_channel_increase.summary()

history_cnn_channel_increase=cnn_channel_increase.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_channel_increase.evaluate(x_test,y_test)

"""<h1>Decreasing channel count per layer<h1/>"""

cnn_channel_decrease=keras.models.Sequential([
    keras.layers.Input(shape=(28, 28, 1)),
    keras.layers.Conv2D(512,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(236,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(64,(3,3),activation="relu",padding="same"),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(64,activation="relu"),
    keras.layers.Dense(10,activation="softmax")
])
cnn_channel_decrease.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_channel_decrease.summary()

history_cnn_channel_decrease=cnn_channel_decrease.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_channel_decrease.evaluate(x_test,y_test)

"""<h1>Kernel low 1x1 <h1/>"""

cnn_kernel_low = keras.models.Sequential([
 keras.layers.Conv2D(64, 7, activation="relu", padding="same",
 input_shape=[28, 28, 1]),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(128, 1, activation="relu", padding="same"),
 keras.layers.Conv2D(128, 1, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(256, 1, activation="relu", padding="same"),
 keras.layers.Conv2D(256, 1, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Flatten(),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(64, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(10, activation="softmax")
])
cnn_kernel_low.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_kernel_low.summary()

history_cnn_kernel_low=cnn_kernel_low.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_kernel_low.evaluate(x_test,y_test)

"""<h1>Kernel high 5x5 <h1/>"""

cnn_kernel_high = keras.models.Sequential([
 keras.layers.Conv2D(64, 7, activation="relu", padding="same",
 input_shape=[28, 28, 1]),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(128, 5, activation="relu", padding="same"),
 keras.layers.Conv2D(128, 5, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Conv2D(256, 5, activation="relu", padding="same"),
 keras.layers.Conv2D(256, 5, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Flatten(),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(64, activation="relu"),
 keras.layers.Dropout(0.5),
 keras.layers.Dense(10, activation="softmax")
])
cnn_kernel_high.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_kernel_high.summary()

history_cnn_kernel_high=cnn_kernel_high.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_kernel_high.evaluate(x_test,y_test)

"""<h1>Deep vs shallow network<h1/>"""

cnn_deep = keras.models.Sequential([
    keras.layers.Conv2D(24, 7, activation="relu",kernel_initializer="he_normal", padding="same",
    input_shape=[28, 28, 1]),
    keras.layers.Conv2D(24, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(64, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.Conv2D(64, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.Flatten(),
    keras.layers.Dense(256,kernel_initializer="he_normal", activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(128,kernel_initializer="he_normal", activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10,kernel_initializer="he_normal", activation="softmax")
])
cnn_deep.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_deep.summary()
# try residual network

def lr_schedule(epoch):
    initial_lr = 0.1
    decay_rate = 0.5
    decay_step = 10
    return initial_lr * (decay_rate ** (epoch // decay_step))

lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)

history_cnn_deep=cnn_deep.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val),callbacks=[lr_scheduler])

cnn_deep.evaluate(x_test,y_test)

"""<h1>Residual network implementation<h1/>"""

import keras
from keras import layers

# Residual Block definition with 1x1 convolution for matching dimensions
def residual_block(x, filters, kernel_size=3):
    # Shortcut connection (input)
    shortcut = x

    # First convolution in the block
    x = layers.Conv2D(filters, kernel_size, activation="relu", kernel_initializer="he_normal", padding="same")(x)

    # Second convolution in the block
    x = layers.Conv2D(filters, kernel_size, activation=None, kernel_initializer="he_normal", padding="same")(x)

    # If the number of filters of the shortcut doesn't match the output, use a 1x1 convolution
    if x.shape[-1] != shortcut.shape[-1]:
        shortcut = layers.Conv2D(filters, 1, kernel_initializer="he_normal", padding="same")(shortcut)

    # Add the shortcut connection to the output of convolutions
    x = layers.add([x, shortcut])

    # ReLU activation after the residual addition
    x = layers.Activation("relu")(x)

    return x

# Build the model with residual blocks
inputs = layers.Input(shape=[28, 28, 1])

x = layers.Conv2D(24, 7, activation="relu", kernel_initializer="he_normal", padding="same")(inputs)
x = layers.Conv2D(24, 3, activation="relu", kernel_initializer="he_normal", padding="same")(x)
x = layers.MaxPooling2D(2)(x)

# First residual block
x = residual_block(x, filters=64)

# Second residual block
x = residual_block(x, filters=64)

x = layers.MaxPooling2D(2)(x)

# Third residual block
x = residual_block(x, filters=128)

# Fourth residual block
x = residual_block(x, filters=128)

# Fifth residual block
x = residual_block(x, filters=128)

x = layers.MaxPooling2D(2)(x)

# Sixth residual block
x = residual_block(x, filters=256)

# Seventh residual block
x = residual_block(x, filters=256)

# Flatten and fully connected layers
x = layers.Flatten()(x)
x = layers.Dense(256, kernel_initializer="he_normal", activation="relu")(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(128, kernel_initializer="he_normal", activation="relu")(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(10, kernel_initializer="he_normal", activation="softmax")(x)

cnn_deep_resnet = keras.models.Model(inputs=inputs, outputs=x)

cnn_deep_resnet.compile(optimizer='adam',
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy'])

cnn_deep_resnet.summary()

history_cnn_deep_resnet=cnn_deep_resnet.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_deep_resnet.evaluate(x_test,y_test)

"""<h1>Shallow network<h1/>"""

cnn_shallow = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu",kernel_initializer="he_normal", padding="same",
    input_shape=[28, 28, 1]),
    keras.layers.Conv2D(128, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(100,kernel_initializer="he_normal", activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10,kernel_initializer="he_normal", activation="softmax")
])
cnn_shallow.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_shallow.summary()

history_cnn_shallow=cnn_shallow.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_shallow.evaluate(x_test,y_test)

import tensorflow as tf
from tensorflow import keras

cnn_global_pool = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu", padding="same", input_shape=[28, 28, 1]),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10, activation="softmax")
])

cnn_global_pool.compile(optimizer='adam',
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy'])
cnn_global_pool.summary()

history_cnn_global_pool=cnn_global_pool.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_global_pool.evaluate(x_test,y_test)

cnn_average_pool = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu", padding="same", input_shape=[28, 28, 1]),
    keras.layers.AveragePooling2D(2),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
    keras.layers.AveragePooling2D(2),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
    keras.layers.AveragePooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10, activation="softmax")
])

cnn_average_pool.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_average_pool.summary()

history_cnn_average_pool=cnn_average_pool.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_average_pool.evaluate(x_test,y_test)

cnn_low_param = keras.models.Sequential([
    keras.layers.Conv2D(1, 3, activation="relu", padding="same", input_shape=[28, 28, 1]),
    keras.layers.Flatten(),
    keras.layers.Dense(10, activation="softmax")
])
cnn_low_param.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_low_param.summary()

history_cnn_low_param=cnn_low_param.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_high_param = keras.models.Sequential([
 keras.layers.Conv2D(128, 7, activation="relu", padding="same",
 input_shape=[28, 28, 1]),
 keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
 keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
 keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
 keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
 keras.layers.MaxPooling2D(2),
 keras.layers.Flatten(),
 keras.layers.Dense(128, activation="relu"),
 keras.layers.Dense(64, activation="relu"),
 keras.layers.Dense(10, activation="softmax")
])
cnn_high_param.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_high_param.summary()

history_cnn_high_param=cnn_high_param.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))



model_names = [
    'cnn_base', 'cnn_channel_increase', 'cnn_channel_decrease',
    'cnn_kernel_low', 'cnn_kernel_high',
    'cnn_deep_resnet', 'cnn_shallow', 'cnn_global_pool','cnn_low_param',
    'cnn_high_param'
]

# List of history objects based on the naming convention
history_names = [globals()[f"history_{model_name}"] for model_name in model_names]
print(model_names,history_names)

def get_model_info(model_names, X_test, y_test):
    model_info = {}

    for model_name in model_names:
        # Get the model from the globals
        model = globals()[model_name]

        # Evaluate model on the test set
        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

        # Get the model's parameter count
        param_count = model.count_params()

        # Store the model's data as a tuple
        model_info[model_name] = (test_loss, test_accuracy, param_count)

    return model_info
plot_info= get_model_info(model_names,x_test,y_test)
print(plot_info)

# Extracting loss values, parameter count, and model names from plot_info
loss_values = [info[0] for info in plot_info.values()]
param_counts = [info[2] for info in plot_info.values()]
model_names = list(plot_info.keys())

# Sort the models by parameter count (ascending order)
sorted_indices = sorted(range(len(param_counts)), key=lambda i: param_counts[i])

# Reorder the data based on the sorted parameter counts
sorted_loss_values = [loss_values[i] for i in sorted_indices]
sorted_param_counts = [param_counts[i] for i in sorted_indices]
sorted_model_names = [model_names[i] for i in sorted_indices]

# Plotting
plt.figure(figsize=(10, 6))
plt.scatter(sorted_param_counts, sorted_loss_values, color='b')  # Scatter plot for the points

# Connect the dots with lines (now ordered by parameter count)
plt.plot(sorted_param_counts, sorted_loss_values, color='gray', linestyle='-', alpha=0.5)

# Automatically label each point with the model name
for i, model_name in enumerate(sorted_model_names):
    plt.text(sorted_param_counts[i], sorted_loss_values[i], model_name, fontsize=9, ha='right')

plt.xlabel('Number of Parameters')
plt.ylabel('Loss')
plt.title('Model Loss vs Parameter Count (Sorted by Parameter Count)')
plt.grid(True)
plt.show()

# Extracting accuracy values, parameter count, and model names from plot_info
accuracy_values = [info[1] for info in plot_info.values()]
param_counts = [info[2] for info in plot_info.values()]
model_names = list(plot_info.keys())

# Sort the models by parameter count (ascending order)
sorted_indices = sorted(range(len(param_counts)), key=lambda i: param_counts[i])

# Reorder the data based on the sorted parameter counts
sorted_accuracy_values = [accuracy_values[i] for i in sorted_indices]
sorted_param_counts = [param_counts[i] for i in sorted_indices]
sorted_model_names = [model_names[i] for i in sorted_indices]

# Plotting
plt.figure(figsize=(10, 6))
plt.scatter(sorted_param_counts, sorted_accuracy_values, color='g')  # Scatter plot for the points

# Connect the dots with lines (now ordered by parameter count)
plt.plot(sorted_param_counts, sorted_accuracy_values, color='gray', linestyle='-', alpha=0.5)

# Automatically label each point with the model name
for i, model_name in enumerate(sorted_model_names):
    plt.text(sorted_param_counts[i], sorted_accuracy_values[i], model_name, fontsize=9, ha='right')

plt.xlabel('Number of Parameters')
plt.ylabel('Accuracy')
plt.title('Model Accuracy vs Parameter Count (Sorted by Parameter Count)')
plt.grid(True)
plt.show()



top_3_models = sorted(plot_info.items(), key=lambda x: x[1][1], reverse=True)[:3]

# Display the top 3 models and their details
for model_name, (test_loss, test_accuracy, param_count) in top_3_models:
    print(f"Model: {model_name}, Accuracy: {test_accuracy:.4f}, Loss: {test_loss:.4f}, Parameters: {param_count}")

def plot_training_history(history):
    train_accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']
    train_loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1, len(train_accuracy) + 1)

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()

    plt.tight_layout()
    plt.show()

from tensorflow.keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_val = x_train[:10000]
y_val = y_train[:10000]
x_train_final = x_train[10000:]
y_train_final = y_train[10000:]
# cnn on cifar
print(
x_train.shape,
x_val.shape,
x_test.shape,
y_train.shape,
y_val.shape,
y_test.shape)
class_names_cifar = [
    'Airplane',    # 0
    'Automobile',  # 1
    'Bird',        # 2
    'Cat',         # 3
    'Deer',        # 4
    'Dog',         # 5
    'Frog',        # 6
    'Horse',       # 7
    'Ship',        # 8
    'Truck'        # 9
]

cnn_shallow = keras.models.Sequential([
    keras.layers.Conv2D(64, 7, activation="relu",kernel_initializer="he_normal", padding="same",
    input_shape=[32, 32, 3]),
    keras.layers.Conv2D(128, 3, activation="relu",kernel_initializer="he_normal", padding="same"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Flatten(),
    keras.layers.Dense(100,kernel_initializer="he_normal", activation="relu"),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10,kernel_initializer="he_normal", activation="softmax")
])
cnn_shallow.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_shallow.summary()
history_cnn_shallow=cnn_shallow.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))

cnn_shallow.evaluate(x_test,y_test)

cnn_channel_increase=keras.models.Sequential([
    keras.layers.Input(shape=(32, 32, 3)),
    keras.layers.Conv2D(64,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(128,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(236,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(512,(3,3),activation="relu"),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(512,activation="relu"),
    keras.layers.Dense(10,activation="softmax")
])
cnn_channel_increase.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_channel_increase.summary()
history_cnn_channel_increase=cnn_channel_increase.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))
plot_training_history(history_cnn_channel_increase)

cnn_channel_increase.evaluate(x_test,y_test)

cnn_channel_decrease=keras.models.Sequential([
    keras.layers.Input(shape=(32, 32, 3)),
    keras.layers.Conv2D(512,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(236,(3,3),activation="relu"),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128,(3,3),activation="relu",padding="same"),
    keras.layers.Conv2D(64,(3,3),activation="relu",padding="same"),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(64,activation="relu"),
    keras.layers.Dense(10,activation="softmax")
])
cnn_channel_decrease.compile(optimizer='adam',
                         loss='sparse_categorical_crossentropy',
                         metrics=['accuracy'])
cnn_channel_decrease.summary()
history_cnn_channel_decrease=cnn_channel_decrease.fit(x_train,y_train,epochs=30,validation_data=(x_val,y_val))
plot_training_history(history_cnn_channel_decrease)

cnn_channel_decrease.evaluate(x_test,y_test)

